# **AstroRAG: Transformer Reranking for Astrophysics Literature Search**

AstroRAG is a retrieval pipeline for astrophysics papers that demonstrates how **transformer bi-encoders** (for fast dense retrieval) and **cross-encoders** (for precise reranking) can improve scientific literature search.  
The project is designed to be reproducible on the **BU SCC** cluster and lightweight enough (~3 GB total) to run locally for demos.

---

## ğŸš€ Project Status

| Phase | Description | Status |
|:------|:-------------|:-------|
| **1. Data Collection** | Harvest astrophysics/physics abstracts from arXiv into JSONL. | âœ… Completed |
| **2. Passage Splitting & Indexing** | Chunk abstracts into overlapping â‰ˆ 100-word passages, embed with MiniLM, and build a FAISS index. | âœ… Completed (293 k passages Ã— 384 dims) |
| **3. Baseline Retrieval Evaluation** | Run title-based queries against FAISS to measure dense retrieval quality (NDCG/MRR/Recall). | âœ… Completed â†’ NDCG@10 = 0.49 Â· MRR@10 = 0.63 Â· Recall@10 = 0.53 |
| **4. Cross-Encoder Reranker** | Fine-tune a transformer (MiniLM / SciBERT) on weakly-supervised (query, passage) pairs. | â³ In progress |
| **5. Evaluation** | Compare retrieval vs reranking using NDCG/MRR on held-out queries. | â³ Pending |
| **6. Visualization & Packaging** | Jupyter notebooks with quantitative plots and qualitative examples. | â³ Pending |

---

## ğŸ—‚ Repo Structure

```
AstroRAG/
â”œâ”€ configs/          # YAML configs
â”œâ”€ data/             # (gitignored) raw + processed data
â”‚  â”œâ”€ raw/           # downloaded arXiv JSONL
â”‚  â”œâ”€ passages.jsonl # chunked passages (Phase 2 output)
â”‚  â””â”€ queries/       # generated title-based queries
â”œâ”€ indexes/          # FAISS indexes + metadata
â”‚  â””â”€ faiss_base/
â”‚     â”œâ”€ index.faiss   # dense vector index
â”‚     â”œâ”€ meta.jsonl    # passage metadata
â”‚     â””â”€ model.txt     # embedding model used
â”œâ”€ outputs/          # (gitignored) models, runs, metrics
â”‚  â”œâ”€ qrels/         # relevance labels
â”‚  â”œâ”€ runs/          # retrieval outputs (TREC format)
â”‚  â””â”€ metrics/       # evaluation JSONs
â”œâ”€ scripts/          # Python scripts for each phase
â”œâ”€ sge/              # SCC GPU/CPU job scripts
â”œâ”€ logs/             # (gitignored) cluster logs
â””â”€ README.md
```

---

## âš™ï¸ Environment Setup

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

On BU SCC (GPU nodes):
```bash
module load pytorch/1.13.1
export HF_HOME=/projectnb/aisearch/$USER/.cache/hf
```

---

## ğŸŒŒ Phase 1: Data Collection

Fetch astrophysics and physics paper metadata from the [arXiv API](https://arxiv.org/help/api/).  
Each record includes **id**, **title**, **abstract**, **authors**, **categories**, and **published date**.

- **Categories pulled:**  
  `astro-ph.CO, astro-ph.GA, astro-ph.EP, astro-ph.HE, astro-ph.IM, astro-ph.SR, gr-qc, physics.comp-ph, physics.space-ph`

- **Script:** [`scripts/00_download_arxiv.py`](scripts/00_download_arxiv.py) â€” polite, resume-safe harvesting with retries.

- **Run:**
  ```bash
  python scripts/00_download_arxiv.py
  ```
- **Output:** `data/raw/arxiv_astro.jsonl`

Example:
```json
{
  "id": "http://arxiv.org/abs/2501.01234v1",
  "title": "Dark matter halos in dwarf galaxies",
  "summary": "We present new results on...",
  "authors": ["A. Author", "B. Author"],
  "categories": ["astro-ph.GA"],
  "published": "2025-01-15T12:00:00Z"
}
```

---

## ğŸ§© Phase 2: Passage Splitting & Indexing

1. **Chunk abstracts:** [`scripts/10_chunk_passages.py`](scripts/10_chunk_passages.py)  
   â†’ splits abstracts into overlapping ~ 100-word passages (title + text).

2. **Embed & index:** [`scripts/20_embed_and_index.py`](scripts/20_embed_and_index.py)  
   â†’ encodes passages with `sentence-transformers/all-MiniLM-L6-v2` and builds a FAISS `IndexFlatIP`.

- **Execution (on GPU):**
  ```bash
  qsub sge/embed_index_gpu.sge
  ```
- **Result:**
  ```
  Indexed 293,969 passages with dim=384 using MiniLM-L6-v2
  ```

- **Outputs (`indexes/faiss_base/`):**
  - `index.faiss` â€” dense vector index  
  - `meta.jsonl` â€” metadata aligned with embeddings  
  - `model.txt` â€” embedding model used

---

## ğŸ“Š Phase 3: Baseline Retrieval Evaluation

Evaluate dense retrieval quality using title-only queries.

```bash
# generate queries
python scripts/30_build_queries.py   --raw_dir data/raw   --out data/queries/dev.jsonl --n 200

# build qrels
python scripts/34_make_qrels.py   --queries data/queries/dev.jsonl   --meta indexes/faiss_base/meta.jsonl   --out outputs/qrels/dev.qrels

# FAISS retrieval
python scripts/31_search_faiss.py   --index indexes/faiss_base/index.faiss   --meta indexes/faiss_base/meta.jsonl   --queries data/queries/dev.jsonl   --out outputs/runs/faiss_dev.trec --topk 100

# evaluation
python scripts/33_eval_runs.py   --qrels outputs/qrels/dev.qrels   --runs outputs/runs/faiss_dev.trec   --out outputs/metrics/dev_faiss.json
```

**Baseline Results (MiniLM dense retriever):**
```json
{
  "NDCG@10": 0.4905,
  "MRR@10": 0.6276,
  "Recall@10": 0.5272
}
```

---

## ğŸ“š Next Steps (Phase 4â€“6)

- **Phase 4:** Generate weakly supervised (query, positive, negative) pairs and train a cross-encoder reranker (`MiniLM`, `SciBERT`).  
- **Phase 5:** Evaluate reranking performance vs FAISS baseline using NDCG/MRR.  
- **Phase 6:** Add Jupyter notebooks with side-by-side retrieval vs rerank visualization and qualitative paper examples.

---

## ğŸ§  Key Concepts

- **Bi-Encoder:** encodes queries and documents separately for fast approximate similarity search (FAISS).  
- **Cross-Encoder:** jointly encodes query + document pairs for higher-precision reranking.  
- **Metrics:** NDCG @ 10, MRR @ 10, Recall @ 10 quantify retrieval relevance and ordering quality.

---

## ğŸª License
MIT
